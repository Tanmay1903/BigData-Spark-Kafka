{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1dc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51796463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c848806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/24 19:46:13 WARN Utils: Your hostname, Tanmays-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.31.18.59 instead (on interface en0)\n",
      "23/05/24 19:46:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/24 19:46:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Set Spark Configuration\n",
    "conf = SparkConf() \\\n",
    "    .setMaster(\"local[*]\") \\\n",
    "    .setAppName(\"WordFrequency\") \\\n",
    "    .setExecutorEnv(\"spark.executor.memory\", \"4g\") \\\n",
    "    .setExecutorEnv(\"spark.driver.memory\", \"4g\")\n",
    "\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf = conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080bbee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=====================================================> (448 + 8) / 459]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('government', 2520220), ('million', 2254837), ('president', 2188344), ('percent', 2022484), ('company', 1665814), ('including', 1594883), ('another', 1536906), ('national', 1415822), ('country', 1295479), ('according', 1281615), ('business', 1275143), ('officials', 1195385), ('american', 1129214), ('international', 1116045), ('financial', 1097723), ('support', 1080820), ('children', 1072798), ('however', 1072381), ('security', 1058058), ('billion', 1048928), ('without', 1039686), ('political', 1018911), ('european', 1018491), ('whether', 1014211), ('yearold', 981085), ('tuesday', 969122), ('already', 960625), ('minister', 942494), ('information', 927617), ('wednesday', 920376), ('reported', 917578), ('expected', 916792), ('economic', 910614), ('thursday', 910326), ('something', 896498), ('military', 893358), ('several', 877379), ('companies', 869823), ('washington', 866771), ('members', 861929), ('service', 853088), ('federal', 852382), ('campaign', 820329), ('statement', 817538), ('economy', 816284), ('british', 813789), ('university', 806440), ('services', 799297), ('director', 788859), ('important', 773495), ('working', 766642), ('players', 755612), ('countries', 740872), ('decision', 732896), ('earlier', 732870), ('different', 722894), ('general', 722260), ('research', 716087), ('capital', 705038), ('saturday', 702016), ('believe', 701737), ('industry', 700053), ('department', 699764), ('executive', 696821), ('quarter', 696623), ('following', 665858), ('although', 662407), ('foreign', 654701), ('despite', 652916), ('official', 643513), ('council', 639576), ('election', 635235), ('announced', 632755), ('looking', 630482), ('possible', 629500), ('thought', 628702), ('control', 628019), ('current', 624575), ('program', 624139), ('getting', 623774), ('interest', 612372), ('outside', 605728), ('england', 599716), ('minutes', 599437), ('spokesman', 596504), ('continue', 594805), ('increase', 588451), ('private', 586730), ('authorities', 584904), ('meeting', 578134), ('history', 576196), ('together', 575984), ('results', 575267), ('community', 571254), ('reports', 565968), ('leaders', 565281), ('problem', 562459), ('hospital', 559119), ('process', 556801), ('markets', 555948)]\n",
      "1284.740023612976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:======================================================>(457 + 2) / 459]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "stopwords = ['i',\n",
    " 'me',\n",
    " 'my',\n",
    " 'myself',\n",
    " 'we',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'you',\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\n",
    " 'he',\n",
    " 'him',\n",
    " 'his',\n",
    " 'himself',\n",
    " 'she',\n",
    " 'her',\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'it',\n",
    " 'its',\n",
    " 'itself',\n",
    " 'they',\n",
    " 'them',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'themselves',\n",
    " 'what',\n",
    " 'which',\n",
    " 'who',\n",
    " 'whom',\n",
    " 'this',\n",
    " 'that',\n",
    " 'these',\n",
    " 'those',\n",
    " 'am',\n",
    " 'is',\n",
    " 'are',\n",
    " 'was',\n",
    " 'were',\n",
    " 'be',\n",
    " 'been',\n",
    " 'being',\n",
    " 'have',\n",
    " 'has',\n",
    " 'had',\n",
    " 'having',\n",
    " 'do',\n",
    " 'does',\n",
    " 'did',\n",
    " 'doing',\n",
    " 'a',\n",
    " 'an',\n",
    " 'the',\n",
    " 'and',\n",
    " 'but',\n",
    " 'if',\n",
    " 'or',\n",
    " 'because',\n",
    " 'as',\n",
    " 'until',\n",
    " 'while',\n",
    " 'of',\n",
    " 'at',\n",
    " 'by',\n",
    " 'for',\n",
    " 'with',\n",
    " 'about',\n",
    " 'against',\n",
    " 'between',\n",
    " 'into',\n",
    " 'through',\n",
    " 'during',\n",
    " 'before',\n",
    " 'after',\n",
    " 'above',\n",
    " 'below',\n",
    " 'to',\n",
    " 'from',\n",
    " 'up',\n",
    " 'down',\n",
    " 'in',\n",
    " 'out',\n",
    " 'on',\n",
    " 'off',\n",
    " 'over',\n",
    " 'under',\n",
    " 'again',\n",
    " 'further',\n",
    " 'then',\n",
    " 'once',\n",
    " 'here',\n",
    " 'there',\n",
    " 'when',\n",
    " 'where',\n",
    " 'why',\n",
    " 'how',\n",
    " 'all',\n",
    " 'any',\n",
    " 'both',\n",
    " 'each',\n",
    " 'few',\n",
    " 'more',\n",
    " 'most',\n",
    " 'other',\n",
    " 'some',\n",
    " 'such',\n",
    " 'no',\n",
    " 'nor',\n",
    " 'not',\n",
    " 'only',\n",
    " 'own',\n",
    " 'same',\n",
    " 'so',\n",
    " 'than',\n",
    " 'too',\n",
    " 'very',\n",
    " 's',\n",
    " 't',\n",
    " 'can',\n",
    " 'will',\n",
    " 'just',\n",
    " 'don',\n",
    " 'should',\n",
    " 'now']\n",
    "\n",
    "# Load the dataset into an RDD (Resilient Distributed Dataset)\n",
    "data_rdd = spark.sparkContext.textFile(\"/Users/tanmaysingla/Downloads/dataset_updated/data_16GB.txt\")\n",
    "\n",
    "# Split each line of the RDD into individual words and convert them to lowercase\n",
    "words_rdd = data_rdd.flatMap(lambda line: line.lower().split(\" \"))\n",
    "\n",
    "# Clean the words RDD\n",
    "clean_words_rdd = words_rdd.map(lambda word: re.sub(r'[^a-zA-Z0-9]', '', word)).filter(lambda x: x != '' and x not in stopwords and len(x) > 6) # and len(x) > 6\n",
    "\n",
    "# Map each word to a count of 1\n",
    "word_counts = clean_words_rdd \\\n",
    "    .map(lambda word: (word, 1))\n",
    "\n",
    "# Reduce by key to get the count of each word\n",
    "word_counts = word_counts \\\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Sort the word counts in descending order\n",
    "sorted_word_counts = word_counts \\\n",
    "    .sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# Take the top 100 words\n",
    "top_100_words = sorted_word_counts \\\n",
    "    .take(100)\n",
    "\n",
    "algo_time = time.time() - start_time\n",
    "print(top_100_words)\n",
    "print(algo_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b35a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rdd = spark.sparkContext.textFile(\"hdfs://localhost:9870/data/input/small_50MB_dataset.txt\").repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b51daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all words in 2.5GB: 239.72171878814697\n",
    "# For words with len > 6 in 2.5GB: 212.92708086967468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1218cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all words in 16GB: 239.72171878814697\n",
    "# For words with len > 6 in 16GB: 1284.740023612976"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
