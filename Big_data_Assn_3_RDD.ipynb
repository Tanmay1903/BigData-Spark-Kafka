{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae061b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4279c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1feb26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/24 22:49:14 WARN Utils: Your hostname, Tanmays-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.123 instead (on interface en0)\n",
      "23/05/24 22:49:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/24 22:49:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Set Spark Configuration\n",
    "conf = SparkConf() \\\n",
    "    .setMaster(\"local[*]\") \\\n",
    "    .setAppName(\"WordFrequency\") \\\n",
    "    .setExecutorEnv(\"spark.executor.memory\", \"4g\") \\\n",
    "    .setExecutorEnv(\"spark.driver.memory\", \"4g\")\n",
    "\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf = conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c723fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================================>(456 + 3) / 459]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('said', 16983022), ('would', 5829046), ('one', 5827766), ('new', 5619230), ('also', 4618215), ('us', 4602714), ('people', 4302072), ('last', 4096901), ('year', 4011799), ('two', 3964133), ('first', 3839806), ('mr', 3733886), ('years', 3637637), ('time', 3635749), ('could', 3374876), ('like', 3058687), ('government', 2520220), ('says', 2417349), ('may', 2393102), ('get', 2346948), ('many', 2344537), ('back', 2295703), ('million', 2254837), ('three', 2250192), ('president', 2188344), ('even', 2175397), ('made', 2130240), ('make', 2104941), ('told', 2092901), ('since', 2041702), ('world', 2039950), ('percent', 2022484), ('police', 2014247), ('well', 1965769), ('still', 1956830), ('state', 1948082), ('way', 1936599), ('much', 1878810), ('say', 1866766), ('day', 1831550), ('week', 1829328), ('home', 1827480), ('take', 1785403), ('per', 1779036), ('work', 1770892), ('going', 1744157), ('think', 1670553), ('company', 1665814), ('good', 1635403), ('dont', 1629480), ('next', 1605312), ('including', 1594883), ('see', 1561684), ('states', 1543090), ('another', 1536906), ('group', 1521292), ('go', 1508944), ('public', 1506216), ('de', 1499252), ('house', 1494729), ('around', 1482328), ('city', 1474865), ('former', 1461398), ('part', 1446434), ('second', 1433374), ('national', 1415822), ('obama', 1405173), ('know', 1386986), ('want', 1379618), ('game', 1371927), ('four', 1371026), ('news', 1368258), ('found', 1366151), ('end', 1353924), ('right', 1336448), ('court', 1330417), ('team', 1329924), ('united', 1310663), ('need', 1307169), ('report', 1299321), ('country', 1295479), ('help', 1289801), ('according', 1281615), ('business', 1275143), ('market', 1267852), ('life', 1256419), ('long', 1241998), ('set', 1232190), ('months', 1227459), ('man', 1226580), ('best', 1211260), ('come', 1208190), ('cent', 1203954), ('officials', 1195385), ('family', 1186523), ('left', 1178731), ('high', 1177790), ('show', 1172154), ('health', 1163667), ('york', 1161010)]\n",
      "1407.3491878509521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "stopwords = ['i',\n",
    " 'me',\n",
    " 'my',\n",
    " 'myself',\n",
    " 'we',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'you',\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\n",
    " 'he',\n",
    " 'him',\n",
    " 'his',\n",
    " 'himself',\n",
    " 'she',\n",
    " 'her',\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'it',\n",
    " 'its',\n",
    " 'itself',\n",
    " 'they',\n",
    " 'them',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'themselves',\n",
    " 'what',\n",
    " 'which',\n",
    " 'who',\n",
    " 'whom',\n",
    " 'this',\n",
    " 'that',\n",
    " 'these',\n",
    " 'those',\n",
    " 'am',\n",
    " 'is',\n",
    " 'are',\n",
    " 'was',\n",
    " 'were',\n",
    " 'be',\n",
    " 'been',\n",
    " 'being',\n",
    " 'have',\n",
    " 'has',\n",
    " 'had',\n",
    " 'having',\n",
    " 'do',\n",
    " 'does',\n",
    " 'did',\n",
    " 'doing',\n",
    " 'a',\n",
    " 'an',\n",
    " 'the',\n",
    " 'and',\n",
    " 'but',\n",
    " 'if',\n",
    " 'or',\n",
    " 'because',\n",
    " 'as',\n",
    " 'until',\n",
    " 'while',\n",
    " 'of',\n",
    " 'at',\n",
    " 'by',\n",
    " 'for',\n",
    " 'with',\n",
    " 'about',\n",
    " 'against',\n",
    " 'between',\n",
    " 'into',\n",
    " 'through',\n",
    " 'during',\n",
    " 'before',\n",
    " 'after',\n",
    " 'above',\n",
    " 'below',\n",
    " 'to',\n",
    " 'from',\n",
    " 'up',\n",
    " 'down',\n",
    " 'in',\n",
    " 'out',\n",
    " 'on',\n",
    " 'off',\n",
    " 'over',\n",
    " 'under',\n",
    " 'again',\n",
    " 'further',\n",
    " 'then',\n",
    " 'once',\n",
    " 'here',\n",
    " 'there',\n",
    " 'when',\n",
    " 'where',\n",
    " 'why',\n",
    " 'how',\n",
    " 'all',\n",
    " 'any',\n",
    " 'both',\n",
    " 'each',\n",
    " 'few',\n",
    " 'more',\n",
    " 'most',\n",
    " 'other',\n",
    " 'some',\n",
    " 'such',\n",
    " 'no',\n",
    " 'nor',\n",
    " 'not',\n",
    " 'only',\n",
    " 'own',\n",
    " 'same',\n",
    " 'so',\n",
    " 'than',\n",
    " 'too',\n",
    " 'very',\n",
    " 's',\n",
    " 't',\n",
    " 'can',\n",
    " 'will',\n",
    " 'just',\n",
    " 'don',\n",
    " 'should',\n",
    " 'now']\n",
    "\n",
    "# Load the dataset into an RDD (Resilient Distributed Dataset)\n",
    "data_rdd = spark.sparkContext.textFile(\"/Users/tanmaysingla/Downloads/dataset_updated/data_16GB.txt\")\n",
    "\n",
    "# Split each line of the RDD into individual words and convert them to lowercase\n",
    "words_rdd = data_rdd.flatMap(lambda line: line.lower().split(\" \"))\n",
    "\n",
    "# Clean the words RDD\n",
    "clean_words_rdd = words_rdd.map(lambda word: re.sub(r'[^a-zA-Z0-9]', '', word)).filter(lambda x: x != '' and x not in stopwords) # and len(x) > 6\n",
    "\n",
    "# Map each word to a count of 1\n",
    "word_counts = clean_words_rdd \\\n",
    "    .map(lambda word: (word, 1))\n",
    "\n",
    "# Reduce by key to get the count of each word\n",
    "word_counts = word_counts \\\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Sort the word counts in descending order\n",
    "sorted_word_counts = word_counts \\\n",
    "    .sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# Take the top 100 words\n",
    "top_100_words = sorted_word_counts \\\n",
    "    .take(100)\n",
    "\n",
    "algo_time = time.time() - start_time\n",
    "print(top_100_words)\n",
    "print(algo_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb2af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_rdd = spark.sparkContext.textFile(\"hdfs://localhost:9870/data/input/small_50MB_dataset.txt\").repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all words in 2.5GB: 239.72171878814697\n",
    "# For words with len > 6 in 2.5GB: 212.92708086967468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all words in 16GB: 1407.3491878509521\n",
    "# For words with len > 6 in 16GB: 1284.740023612976"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
